{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "\n",
    "# Import MTCNN for face detection\n",
    "from mtcnn import MTCNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "TIME_STEPS = 30  # Number of frames per video\n",
    "HEIGHT, WIDTH = 299, 299\n",
    "\n",
    "# Paths\n",
    "model_path = '/content/drive/MyDrive/Dataset DDM/FINAL models/COMBINED_best_Phase1.keras'  # Update with your model path\n",
    "# video_path = '/content/drive/MyDrive/Dataset DDM/Saved models_trial 1/demo 2.mp4'  # Update with your video path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_faces_from_video(video_path, num_frames=TIME_STEPS):\n",
    "    \"\"\"\n",
    "    Extracts faces from a video file using MTCNN, resizes them to 299x299,\n",
    "    and returns a list of preprocessed face images.\n",
    "    \"\"\"\n",
    "    # Initialize MTCNN face detector\n",
    "    detector = MTCNN()\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frames = []\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_indices = np.linspace(0, frame_count - 1, num_frames, dtype=int)\n",
    "\n",
    "    idx = 0\n",
    "    success = True\n",
    "    while success and len(frames) < num_frames:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        if idx in frame_indices:\n",
    "            # Convert frame to RGB\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # Detect faces in the frame\n",
    "            detections = detector.detect_faces(frame_rgb)\n",
    "            if detections:\n",
    "                # If faces are detected, take the first one\n",
    "                x, y, width, height = detections[0]['box']\n",
    "                # Ensure the bounding box is within the frame\n",
    "                x, y = max(0, x), max(0, y)\n",
    "                x2, y2 = x + width, y + height\n",
    "                face = frame_rgb[y:y2, x:x2]\n",
    "                # Resize to 299x299\n",
    "                face_image = Image.fromarray(face).resize((WIDTH, HEIGHT))\n",
    "                # Preprocess the image\n",
    "                face_array = np.array(face_image)\n",
    "                face_array = preprocess_input(face_array)\n",
    "                frames.append(face_array)\n",
    "            else:\n",
    "                # If no face is detected, use a black image\n",
    "                face_array = np.zeros((HEIGHT, WIDTH, 3), dtype=np.float32)\n",
    "                frames.append(face_array)\n",
    "        idx += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # If fewer frames were collected, pad with the last frame\n",
    "    if len(frames) < num_frames:\n",
    "        if frames:\n",
    "            last_frame = frames[-1]\n",
    "        else:\n",
    "            # If no frames were collected, use a black image\n",
    "            last_frame = np.zeros((HEIGHT, WIDTH, 3), dtype=np.float32)\n",
    "        frames += [last_frame] * (num_frames - len(frames))\n",
    "\n",
    "    # Convert to NumPy array and add batch dimension\n",
    "    video_array = np.array(frames)  # Shape: (num_frames, HEIGHT, WIDTH, 3)\n",
    "    video_array = np.expand_dims(video_array, axis=0)  # Shape: (1, num_frames, HEIGHT, WIDTH, 3)\n",
    "    return video_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(lstm_hidden_size=256, num_classes=2, dropout_rate=0.5):\n",
    "    # Input shape: (batch_size, TIME_STEPS, HEIGHT, WIDTH, 3)\n",
    "    inputs = layers.Input(shape=(TIME_STEPS, HEIGHT, WIDTH, 3))\n",
    "\n",
    "    # TimeDistributed layer to apply the base model to each frame\n",
    "    base_model = keras.applications.Xception(weights='imagenet', include_top=False, pooling='avg')\n",
    "    # For inference, we don't need to set trainable, but if you plan to retrain, you can set accordingly\n",
    "    # base_model.trainable = False\n",
    "\n",
    "    # Apply TimeDistributed wrapper\n",
    "    x = layers.TimeDistributed(base_model)(inputs)\n",
    "    # x shape: (batch_size, TIME_STEPS, 2048)\n",
    "\n",
    "    # LSTM layer\n",
    "    x = layers.LSTM(lstm_hidden_size)(x)\n",
    "\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Load the model architecture\n",
    "model = build_model()\n",
    "# Load weights into the model\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '/content/drive/MyDrive/Dataset DDM/FF++/manipulated_sequences/FaceShifter/raw/videos/724_725.mp4'\n",
    "\n",
    "# Process the video and get the preprocessed frames\n",
    "video_array = extract_faces_from_video(video_path, num_frames=TIME_STEPS)\n",
    "\n",
    "# Make prediction\n",
    "predictions = model.predict(video_array)\n",
    "# Get the predicted class (0 for real, 1 for fake)\n",
    "predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "# Get class probabilities\n",
    "probabilities = predictions[0]\n",
    "\n",
    "# Output the results\n",
    "class_names = ['Real', 'Fake']\n",
    "print(f\"Predicted Class: {class_names[predicted_class]}\")\n",
    "print(f\"Class Probabilities: Real: {probabilities[0]:.4f}, Fake: {probabilities[1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
